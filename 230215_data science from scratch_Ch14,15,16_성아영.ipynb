{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AY\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "x = np.array(df['RM'])\n",
    "y = np.array(df['target'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_x = scaler.fit_transform(x.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_fit(x, y):\n",
    "    w = np.corrcoef(x, y) * np.std(y) / np.std(x)\n",
    "    b = np.mean(y) - w * np.mean(x)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b)-> float:\n",
    "    return x * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x, w, b, y)-> float:\n",
    "    error = (y - predict(x, w, b))**2 / len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(x, w, b, y)-> float:\n",
    "    error = MSE(x, w, b, y)\n",
    "    return 1 / 2 * error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 7.76495, b = -13.80511 error = 482.17422\n",
      " 5 w = 6.00657, b = -14.09420 error = 51.03097\n",
      "10 w = 5.88242, b = -14.12638 error = 48.81261\n",
      "15 w = 5.87533, b = -14.14015 error = 48.79501\n",
      "20 w = 5.87662, b = -14.15259 error = 48.78871\n",
      "25 w = 5.87851, b = -14.16493 error = 48.78247\n",
      "30 w = 5.88045, b = -14.17725 error = 48.77625\n",
      "35 w = 5.88238, b = -14.18957 error = 48.77003\n",
      "40 w = 5.88432, b = -14.20188 error = 48.76381\n",
      "45 w = 5.88625, b = -14.21418 error = 48.75761\n",
      "50 w = 5.88819, b = -14.22648 error = 48.75141\n",
      "55 w = 5.89012, b = -14.23876 error = 48.74522\n",
      "60 w = 5.89205, b = -14.25104 error = 48.73904\n",
      "65 w = 5.89398, b = -14.26332 error = 48.73286\n",
      "70 w = 5.89591, b = -14.27558 error = 48.72670\n",
      "75 w = 5.89783, b = -14.28784 error = 48.72054\n",
      "80 w = 5.89976, b = -14.30009 error = 48.71438\n",
      "85 w = 5.90168, b = -14.31234 error = 48.70824\n",
      "90 w = 5.90361, b = -14.32457 error = 48.70210\n",
      "95 w = 5.90553, b = -14.33680 error = 48.69597\n",
      "------------------------------------------------------------\n",
      "99 w = 5.90707, b = -14.34658 error = 48.69107\n"
     ]
    }
   ],
   "source": [
    "# gradient desent\n",
    "num_epoch = 100\n",
    "errors = []\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 초기 w,b 랜덤 설정\n",
    "w = np.random.uniform(low=9.0, high=10.0)\n",
    "b = np.random.uniform(low=-40.0, high=-10.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = predict(x, w, b)\n",
    "    error = np.mean(((y_predict - y)**2))\n",
    "    if error < 0.0005:\n",
    "        break\n",
    "\n",
    "    w = w - learning_rate * ((y_predict - y) * x).mean()\n",
    "    b = b - learning_rate * (y_predict - y).mean() \n",
    "\n",
    "    errors.append(error)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24045bf4d30>]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, predict(x, w, b), color='red')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_odds(features, coefficients, intercept):\n",
    "  z = np.dot(features, coefficients) + intercept\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_pred, y_true):\n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "  log_loss = -1 * np.mean( y_true*np.log10(y_pred) \\\n",
    "                          + (1-y_true)*np.log10(1-y_pred)) \n",
    "  return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_db(x, y, w, b):\n",
    "  db = y-sigmoid(np.dot(w.T,x)+b)\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_dw(x, y, w, b, alpha, N):\n",
    "  dw = x * (y-sigmoid(np.dot(w.T,x)+b)) - ((alpha*w*w)/N)\n",
    "  return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(features, coefficients, intercept, threshold):\n",
    "  z = log_odds(features, coefficients, intercept)\n",
    "  a = sigmoid(z)\n",
    "\n",
    "  return np.where(a >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AY\\AppData\\Local\\Temp\\ipykernel_19524\\3395817780.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  log_loss = -1 * np.mean( y_true*np.log10(y_pred) \\\n",
      "C:\\Users\\AY\\AppData\\Local\\Temp\\ipykernel_19524\\3395817780.py:5: RuntimeWarning: divide by zero encountered in log10\n",
      "  + (1-y_true)*np.log10(1-y_pred))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 생성\n",
    "X, y = make_classification(n_samples = 50000, n_features = 15, \n",
    "                    n_informative = 10, n_redundant = 5, \n",
    "                    n_classes = 2, weights = [0.7], \n",
    "                    class_sep = 0.7, random_state=15)\n",
    "\n",
    "# 데이터 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                    random_state = 15)\n",
    "\n",
    "# 데이터 정규화 \n",
    "scaler = StandardScaler()\n",
    "x_train_standard = scaler.fit_transform(X_train)\n",
    "x_test_standard = scaler.transform(X_test)\n",
    "\n",
    "# w, b 초기화\n",
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "\n",
    "# 학습률, 반복 설정\n",
    "alpha  = 0.0001\n",
    "eta0   = 0.0001\n",
    "epochs = 50\n",
    "\n",
    "N = len(X_train)\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    for j in range(N):\n",
    "        grad_dw = gradient_dw(x_train_standard[j], y_train[j], w, b, alpha, N)\n",
    "        grad_db = gradient_db(x_train_standard[j], y_train[j], w, b)\n",
    "        w = np.array(w) + (eta0 * np.array(grad_dw))\n",
    "        b = b + (eta0 * grad_db)\n",
    "\n",
    "    predict_train = []\n",
    "    for m in range(len(y_train)):\n",
    "        z = np.dot(w, x_train_standard[m])+b\n",
    "        predict_train.append(sigmoid(z)) \n",
    "    \n",
    "    train_loss = log_loss(y_train, predict_train)\n",
    "\n",
    "    predict_test = []\n",
    "    for m in range(len(y_test)):\n",
    "        z = np.dot(w, x_test_standard[m])+b\n",
    "        predict_test.append(sigmoid(z))\n",
    "    \n",
    "    test_loss = log_loss(y_test, predict_test)\n",
    "\n",
    "\n",
    "    if log_loss_train and train_loss > log_loss_train[-1]: \n",
    "        break\n",
    "    \n",
    "    log_loss_train.append(train_loss)\n",
    "    log_loss_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight vector:  [-0.97125471  0.6951594  -0.1064887   0.68159065 -0.4447256   1.00799626\n",
      " -0.94341151 -0.07316669  0.44633501  0.47814799  0.27402291  0.06013621\n",
      " -0.09610527  0.57042941  0.06404642]\n",
      "Intercept:  -1.3691399553813899\n"
     ]
    }
   ],
   "source": [
    "print (\"weight vector: \", w)\n",
    "print (\"Intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.08 seconds.\n",
      "Convergence after 14 epochs took 0.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(eta0 = 0.0001, loss='log', alpha=0.0001, \n",
    "              random_state=15, penalty='l2', tol=1e-3, \n",
    "              verbose=2, learning_rate='constant')\n",
    "clf.fit(x_train_standard, y_train)\n",
    "clf.coef_, clf.intercept_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_odds(features, coefficients, intercept):\n",
    "  z = np.dot(features, coefficietns) + intercept\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_pred, y_true):\n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "  log_loss = -1 * np.mean( y_true*np.log10(y_pred) + (1-y_true)*np.log10(1-y_pred)) \n",
    "  return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_db(x, y, w, b):\n",
    "  db = y-sigmoid(np.dot(w.T,x)+b)\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_dw(x, y, w, b, alpha, N):\n",
    "  dw = x * (y-sigmoid(np.dot(w.T,x)+b)) - ((alpha*w*w)/N)\n",
    "  return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(features, coefficients, intercept, threshold):\n",
    "  z = log_odds(features, coefficients, intercept)\n",
    "  a = sigmoid(z)\n",
    "\n",
    "  return np.where(a >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AY\\AppData\\Local\\Temp\\ipykernel_17504\\3679002326.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  log_loss = -1 * np.mean( y_true*np.log10(y_pred) + (1-y_true)*np.log10(1-y_pred))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 생성\n",
    "X, y = make_classification(n_samples = 50000, n_features = 15, \n",
    "                    n_informative = 10, n_redundant = 5, \n",
    "                    n_classes = 2, weights = [0.7], \n",
    "                    class_sep = 0.7, random_state=15)\n",
    "\n",
    "# 데이터 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                    random_state = 15)\n",
    "\n",
    "# 데이터 정규화 \n",
    "scaler = StandardScaler()\n",
    "x_train_standard = scaler.fit_transform(X_train)\n",
    "x_test_standard = scaler.transform(X_test)\n",
    "\n",
    "# w, b 초기화\n",
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "\n",
    "# 학습률, 반복 설정\n",
    "alpha  = 0.0001\n",
    "eta0   = 0.0001\n",
    "epochs = 50\n",
    "\n",
    "N = len(X_train)\n",
    "log_loss_train = []\n",
    "log_loss_test = []\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    for j in range(N):\n",
    "        grad_dw = gradient_dw(x_train_standard[j], y_train[j], w, b, alpha, N)\n",
    "        grad_db = gradient_db(x_train_standard[j], y_train[j], w, b)\n",
    "        w = np.array(w) + (eta0 * np.array(grad_dw))\n",
    "        b = b + (eta0 * grad_db)\n",
    "\n",
    "    predict_train = []\n",
    "    for m in range(len(y_train)):\n",
    "        z = np.dot(w, x_train_standard[m])+b\n",
    "        predict_train.append(sigmoid(z)) \n",
    "    \n",
    "    train_loss = log_loss(y_train, predict_train)\n",
    "\n",
    "    predict_test = []\n",
    "    for m in range(len(y_test)):\n",
    "        z = np.dot(w, x_test_standard[m])+b\n",
    "        predict_test.append(sigmoid(z))\n",
    "    \n",
    "    test_loss = log_loss(y_test, predict_test)\n",
    "\n",
    "\n",
    "    if log_loss_train and train_loss > log_loss_train[-1]: \n",
    "        break\n",
    "    \n",
    "    log_loss_train.append(train_loss)\n",
    "    log_loss_test.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight vector:  [-0.97125471  0.6951594  -0.1064887   0.68159065 -0.4447256   1.00799626\n",
      " -0.94341151 -0.07316669  0.44633501  0.47814799  0.27402291  0.06013621\n",
      " -0.09610527  0.57042941  0.06404642]\n",
      "Intercept:  -1.3691399553813899\n"
     ]
    }
   ],
   "source": [
    "print (\"weight vector: \", w)\n",
    "print (\"Intercept: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 14 epochs took 0.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(eta0 = 0.0001, loss='log', alpha=0.0001, \n",
    "              random_state=15, penalty='l2', tol=1e-3, \n",
    "              verbose=2, learning_rate='constant')\n",
    "clf.fit(x_train_standard, y_train)\n",
    "clf.coef_, clf.intercept_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 8.12869, b = -17.01974 error = 415.96292\n",
      " 5 w = 6.51433, b = -17.28987 error = 49.49931\n",
      "10 w = 6.39998, b = -17.32360 error = 47.34708\n",
      "15 w = 6.39396, b = -17.34026 error = 47.31243\n",
      "20 w = 6.39576, b = -17.35567 error = 47.30453\n",
      "25 w = 6.39813, b = -17.37099 error = 47.29791\n",
      "30 w = 6.40054, b = -17.38629 error = 47.29139\n",
      "35 w = 6.40295, b = -17.40159 error = 47.28488\n",
      "40 w = 6.40536, b = -17.41687 error = 47.27839\n",
      "45 w = 6.40777, b = -17.43215 error = 47.27190\n",
      "50 w = 6.41018, b = -17.44743 error = 47.26542\n",
      "55 w = 6.41258, b = -17.46269 error = 47.25895\n",
      "60 w = 6.41499, b = -17.47795 error = 47.25249\n",
      "65 w = 6.41739, b = -17.49320 error = 47.24604\n",
      "70 w = 6.41979, b = -17.50845 error = 47.23959\n",
      "75 w = 6.42219, b = -17.52368 error = 47.23316\n",
      "80 w = 6.42459, b = -17.53891 error = 47.22673\n",
      "85 w = 6.42699, b = -17.55414 error = 47.22032\n",
      "90 w = 6.42939, b = -17.56935 error = 47.21391\n",
      "95 w = 6.43179, b = -17.58456 error = 47.20751\n",
      "------------------------------------------------------------\n",
      "99 w = 6.43370, b = -17.59672 error = 47.20239\n"
     ]
    }
   ],
   "source": [
    "# gradient desent\n",
    "num_epoch = 100\n",
    "errors = []\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.01\n",
    "lr = 0.001\n",
    "\n",
    "# 초기 w,b 랜덤 설정\n",
    "w = np.random.uniform(low=9.0, high=10.0)\n",
    "b = np.random.uniform(low=-40.0, high=-10.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = predict(x, w, b)\n",
    "    error = np.mean(((y_predict - y)**2))\n",
    "    if error < 0.0005:\n",
    "        break\n",
    "\n",
    "    w = w - learning_rate * ((y_predict - y) * x).mean()+ lr * np.sum(np.abs(w))\n",
    "    b = b - learning_rate * (y_predict - y).mean() \n",
    "\n",
    "    errors.append(error)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 9.60701, b = -34.18808 error = 70.48987\n",
      " 5 w = 9.28504, b = -34.30865 error = 46.29967\n",
      "10 w = 9.26814, b = -34.37909 error = 45.42297\n",
      "15 w = 9.27669, b = -34.44545 error = 45.36489\n",
      "20 w = 9.28738, b = -34.51158 error = 45.36742\n",
      "25 w = 9.29826, b = -34.57779 error = 45.37509\n",
      "30 w = 9.30919, b = -34.64412 error = 45.38334\n",
      "35 w = 9.32013, b = -34.71056 error = 45.39177\n",
      "40 w = 9.33109, b = -34.77711 error = 45.40036\n",
      "45 w = 9.34207, b = -34.84379 error = 45.40910\n",
      "50 w = 9.35307, b = -34.91058 error = 45.41800\n",
      "55 w = 9.36409, b = -34.97749 error = 45.42706\n",
      "60 w = 9.37513, b = -35.04452 error = 45.43627\n",
      "65 w = 9.38619, b = -35.11166 error = 45.44565\n",
      "70 w = 9.39728, b = -35.17893 error = 45.45518\n",
      "75 w = 9.40838, b = -35.24631 error = 45.46487\n",
      "80 w = 9.41950, b = -35.31381 error = 45.47473\n",
      "85 w = 9.43064, b = -35.38144 error = 45.48474\n",
      "90 w = 9.44181, b = -35.44918 error = 45.49492\n",
      "95 w = 9.45299, b = -35.51704 error = 45.50526\n",
      "------------------------------------------------------------\n",
      "99 w = 9.46195, b = -35.57142 error = 45.51366\n"
     ]
    }
   ],
   "source": [
    "# gradient desent\n",
    "num_epoch = 100\n",
    "errors = []\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.01\n",
    "lr = 0.001\n",
    "\n",
    "# 초기 w,b 랜덤 설정\n",
    "w = np.random.uniform(low=9.0, high=10.0)\n",
    "b = np.random.uniform(low=-40.0, high=-10.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = predict(x, w, b)\n",
    "    error = np.mean(((y_predict - y)**2))\n",
    "    if error < 0.0005:\n",
    "        break\n",
    "\n",
    "    w = w - learning_rate * ((y_predict - y) * x).mean()+ lr * np.sum(np.square(w))\n",
    "    b = b - learning_rate * (y_predict - y).mean() \n",
    "\n",
    "    errors.append(error)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 10 ** 9 # 매우 큰 값으로 초기값 가정\n",
    "limit = 3 # 몇 번의 epoch까지 지켜볼지를 결정\n",
    "check = 0 # 현재 몇 epoch 연속으로 loss 개선이 안되는지를 기록\n",
    "\n",
    "### 전체 학습 코드 스니펫 ###\n",
    "for i in range(epochs):\n",
    "\t\n",
    "    ### 각 epoch의 train 부분 ###\n",
    "    model.train()\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ### 각 epoch train 이후 evaluation 진행 ###\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    for X, y in eval_dataloader:\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_function(y_pred, y)\n",
    "\n",
    "        val_loss += loss.item()   \n",
    "        \n",
    "    ### early stopping 여부를 체크하는 부분 ###\n",
    "    if val_loss > best_loss: # loss가 개선되지 않은 경우\n",
    "        patience_check += 1\n",
    "\n",
    "        if patience_check >= patience_limit: # early stopping 조건 만족 시 조기 종료\n",
    "            break\n",
    "\n",
    "    else: # loss가 개선된 경우\n",
    "        best_loss = val_loss\n",
    "        patience_check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 8.84315, b = -28.51546 error = 88.80058\n",
      " 5 w = 8.36923, b = -28.65137 error = 46.38757\n",
      "10 w = 8.33880, b = -28.71463 error = 45.26418\n",
      "15 w = 8.34486, b = -28.77199 error = 45.18496\n",
      "20 w = 8.35392, b = -28.82896 error = 45.17575\n",
      "25 w = 8.36324, b = -28.88596 error = 45.17227\n",
      "30 w = 8.37259, b = -28.94305 error = 45.16935\n",
      "35 w = 8.38196, b = -29.00023 error = 45.16656\n",
      "40 w = 8.39135, b = -29.05749 error = 45.16387\n",
      "45 w = 8.40075, b = -29.11484 error = 45.16128\n",
      "50 w = 8.41016, b = -29.17227 error = 45.15878\n",
      "55 w = 8.41959, b = -29.22979 error = 45.15638\n",
      "60 w = 8.42903, b = -29.28740 error = 45.15407\n",
      "65 w = 8.43849, b = -29.34509 error = 45.15186\n",
      "70 w = 8.44797, b = -29.40288 error = 45.14975\n",
      "75 w = 8.45746, b = -29.46075 error = 45.14774\n",
      "80 w = 8.46696, b = -29.51871 error = 45.14582\n",
      "85 w = 8.47648, b = -29.57675 error = 45.14400\n",
      "90 w = 8.48601, b = -29.63489 error = 45.14229\n",
      "95 w = 8.49556, b = -29.69311 error = 45.14067\n",
      "100 w = 8.50512, b = -29.75143 error = 45.13915\n",
      "105 w = 8.51470, b = -29.80983 error = 45.13773\n",
      "110 w = 8.52430, b = -29.86832 error = 45.13642\n",
      "115 w = 8.53390, b = -29.92691 error = 45.13521\n",
      "120 w = 8.54353, b = -29.98558 error = 45.13410\n",
      "125 w = 8.55317, b = -30.04435 error = 45.13309\n",
      "130 w = 8.56282, b = -30.10320 error = 45.13219\n",
      "135 w = 8.57249, b = -30.16215 error = 45.13139\n",
      "140 w = 8.58218, b = -30.22119 error = 45.13069\n",
      "145 w = 8.59188, b = -30.28032 error = 45.13010\n",
      "150 w = 8.60160, b = -30.33954 error = 45.12962\n",
      "155 w = 8.61133, b = -30.39886 error = 45.12924\n",
      "160 w = 8.62108, b = -30.45826 error = 45.12897\n",
      "165 w = 8.63085, b = -30.51776 error = 45.12880\n",
      "170 w = 8.64063, b = -30.57736 error = 45.12875\n",
      "175 w = 8.65042, b = -30.63705 error = 45.12880\n",
      "180 w = 8.66023, b = -30.69683 error = 45.12896\n",
      "185 w = 8.67006, b = -30.75670 error = 45.12923\n",
      "190 w = 8.67991, b = -30.81667 error = 45.12961\n",
      "195 w = 8.68977, b = -30.87674 error = 45.13010\n",
      "200 w = 8.69964, b = -30.93690 error = 45.13070\n",
      "205 w = 8.70953, b = -30.99716 error = 45.13142\n",
      "210 w = 8.71944, b = -31.05751 error = 45.13225\n",
      "215 w = 8.72937, b = -31.11796 error = 45.13319\n",
      "220 w = 8.73931, b = -31.17850 error = 45.13424\n",
      "225 w = 8.74927, b = -31.23914 error = 45.13541\n",
      "230 w = 8.75924, b = -31.29988 error = 45.13669\n",
      "235 w = 8.76923, b = -31.36072 error = 45.13809\n",
      "240 w = 8.77924, b = -31.42165 error = 45.13960\n",
      "245 w = 8.78926, b = -31.48268 error = 45.14123\n",
      "250 w = 8.79930, b = -31.54381 error = 45.14298\n",
      "255 w = 8.80936, b = -31.60504 error = 45.14485\n",
      "260 w = 8.81943, b = -31.66637 error = 45.14683\n",
      "265 w = 8.82952, b = -31.72779 error = 45.14894\n",
      "------------------------------------------------------------\n",
      "270 w = 8.83963, b = -31.78932 error = 45.15116\n"
     ]
    }
   ],
   "source": [
    "# gradient desent\n",
    "num_epoch = 10000\n",
    "errors = []\n",
    "\n",
    "# limit epoch 설정\n",
    "limit = 100\n",
    "# 현재 몇 epoch 연속으로 loss 개선이 안되는지를 기록\n",
    "check = 0 \n",
    "best_loss = 9999\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 초기 w,b 랜덤 설정\n",
    "w = np.random.uniform(low=9.0, high=10.0)\n",
    "b = np.random.uniform(low=-40.0, high=-10.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = predict(x, w, b)\n",
    "    error = np.mean(((y_predict - y)**2))\n",
    "    \n",
    "    if error < 0.0005:\n",
    "        break\n",
    "\n",
    "    w = w - learning_rate * ((y_predict - y) * x).mean()+ lr * np.sum(np.square(w))\n",
    "    b = b - learning_rate * (y_predict - y).mean() \n",
    "\n",
    "    errors.append(error)\n",
    "    \n",
    "    # EARLY STOPPING\n",
    "    if best_loss < error:\n",
    "        check += 1\n",
    "        if check >= limit:\n",
    "            break\n",
    "    else:\n",
    "        best_loss = error\n",
    "        check = 0\n",
    "\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}\".format(epoch, w, b, error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X, drop_prob):\n",
    "    assert 0 <= drop_prob <= 1\n",
    "    \n",
    "    if drop_prob == 1:\n",
    "        return np.zeros_like(X)\n",
    "    mask = np.random.uniform(0, 1, X.shape) > drop_prob\n",
    "    return mask * X / (1.0-drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
      "[[ 0.          1.42857143  0.          0.          5.71428571  7.14285714\n",
      "   8.57142857 10.        ]\n",
      " [ 0.          0.         14.28571429  0.         17.14285714  0.\n",
      "  20.          0.        ]]\n",
      "[[ 0.  0.  4.  0.  0.  0.  0. 14.]\n",
      " [16. 18. 20.  0. 24.  0.  0. 30.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(16).reshape((2, 8))\n",
    "print(dropout(X, 0))\n",
    "print(dropout(X, 0.3))\n",
    "print(dropout(X, 0.5))\n",
    "print(dropout(X, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c73bdefccaf48e728a83183c4b62184225f554a39082c36ad770ba68b989c4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
